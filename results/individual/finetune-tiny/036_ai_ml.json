{
  "audio_file": "036_ai_ml",
  "model": "finetune-tiny",
  "reference": "The tokenizer splits text into subword units before feeding it to the model. Different tokenizers handle special characters and numbers in different ways.",
  "hypothesis": "The tokenizer split text into subword units before feeding it to the model. Different tokenizers handle special characters and numbers in different ways.",
  "reference_normalized": "the tokenizer splits text into subword units before feeding it to the model different tokenizers handle special characters and numbers in different ways",
  "hypothesis_normalized": "the tokenizer split text into subword units before feeding it to the model different tokenizers handle special characters and numbers in different ways",
  "wer": 0.043478260869565216,
  "duration_seconds": 0.24311184883117676
}