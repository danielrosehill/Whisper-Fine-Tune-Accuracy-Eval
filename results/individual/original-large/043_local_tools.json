{
  "audio_file": "043_local_tools",
  "model": "original-large",
  "reference": "The CTranslate2 version of the model runs inference twice as fast. It optimizes the computation graph and supports int8 quantization out of the box.",
  "hypothesis": "The CTranslate 2 version of the model runs inference twice as fast. It optimizes the computation graph and supports intake quantization out of the box.",
  "reference_normalized": "the ctranslate 2 version of the model runs inference twice as fast it optimizes the computation graph and supports int 8 quantization out of the box",
  "hypothesis_normalized": "the ctranslate 2 version of the model runs inference twice as fast it optimizes the computation graph and supports intake quantization out of the box",
  "wer": 0.07692307692307693,
  "duration_seconds": 0.9893035888671875
}