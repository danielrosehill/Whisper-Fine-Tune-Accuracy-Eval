{
  "audio_file": "036_ai_ml",
  "model": "finetune-large",
  "reference": "The tokenizer splits text into subword units before feeding it to the model. Different tokenizers handle special characters and numbers in different ways.",
  "hypothesis": "The tokenizer splits text into sub-word units before feeding it to the model. Different tokenizers handle special characters and numbers in different ways.",
  "reference_normalized": "the tokenizer splits text into subword units before feeding it to the model different tokenizers handle special characters and numbers in different ways",
  "hypothesis_normalized": "the tokenizer splits text into sub word units before feeding it to the model different tokenizers handle special characters and numbers in different ways",
  "wer": 0.08695652173913043,
  "duration_seconds": 1.003903865814209
}