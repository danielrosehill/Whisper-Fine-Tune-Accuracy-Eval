{
  "audio_file": "036_ai_ml",
  "model": "finetune-medium",
  "reference": "The tokenizer splits text into subword units before feeding it to the model. Different tokenizers handle special characters and numbers in different ways.",
  "hypothesis": "The tokenizer splits text into subword units before feeding it to the model. Different tokenizers handle special characters and numbers in different ways.",
  "reference_normalized": "the tokenizer splits text into subword units before feeding it to the model different tokenizers handle special characters and numbers in different ways",
  "hypothesis_normalized": "the tokenizer splits text into subword units before feeding it to the model different tokenizers handle special characters and numbers in different ways",
  "wer": 0.0,
  "duration_seconds": 1.0520296096801758
}