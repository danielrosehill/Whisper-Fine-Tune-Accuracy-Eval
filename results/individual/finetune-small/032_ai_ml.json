{
  "audio_file": "032_ai_ml",
  "model": "finetune-small",
  "reference": "I am training a LoRA adapter instead of doing full fine tuning. It uses much less memory and the resulting weights are only a few megabytes.",
  "hypothesis": "I am training a Lora adapter instead of doing full fine-tuning. It uses much less memory, and the resulting weights are only a few megabytes.",
  "reference_normalized": "i am training a lora adapter instead of doing full fine tuning it uses much less memory and the resulting weights are only a few megabytes",
  "hypothesis_normalized": "i am training a lora adapter instead of doing full fine tuning it uses much less memory and the resulting weights are only a few megabytes",
  "wer": 0.0,
  "duration_seconds": 0.5768070220947266
}